# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hu-pnauG4tlPFYCiXE06LfLfZ3VDOXgc
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv("/content/drive/MyDrive/municipality_bus_utilization_.csv", sep=' ')
print(df.head)

df1 = pd.read_csv("/content/drive/MyDrive/municipality_bus_utilization_.csv", delimiter=",",skiprows=[0], header=0, names=["timestamp", "municipality_id", "usage", "total_capacity"])
df1

"""**Preprocessing Steps**"""

def check_missing_values(df1):
    missing_values = df1.isnull().sum().sum()
    if missing_values > 0:
        print("Veri kümesi boş değerler içeriyor.")
    else:
        print("Veri kümesi boş değerler içermiyor.")

check_missing_values(df1)

import seaborn as sns


sns.boxplot(data=df1)

import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

class DataPreprocessor:
    def __init__(self, data_path):
        self.data_path = data_path
        self.data = None

    def load_data(self):
        self.data = pd.read_csv(self.data_path)

    def handle_missing_values(self):
        imputer = SimpleImputer(strategy='mean')
        self.data['usage'] = imputer.fit_transform(self.data['usage'].values.reshape(-1, 1))
        self.data['total_capacity'] = imputer.fit_transform(self.data['total_capacity'].values.reshape(-1, 1))

    def encode_categorical_features(self):
        label_encoder = LabelEncoder()
        self.data['municipality_id'] = label_encoder.fit_transform(self.data['municipality_id'])

        one_hot_encoder = OneHotEncoder(sparse_output=False)
        encoded_features = one_hot_encoder.fit_transform(self.data['municipality_id'].values.reshape(-1, 1))
        encoded_features_df = pd.DataFrame(encoded_features, columns=['municipality_' + str(i) for i in range(encoded_features.shape[1])])
        self.data = pd.concat([self.data, encoded_features_df], axis=1)

    def preprocess_data(self):
        self.load_data()
        self.handle_missing_values()
        self.encode_categorical_features()
        return self.data

# Örnek kullanım:
data_path = '/content/drive/MyDrive/municipality_bus_utilization_.csv'  # Veri kümesinin dosya yolu
preprocessor = DataPreprocessor(data_path)
preprocessed_data = preprocessor.preprocess_data()
print(preprocessed_data.head())

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

class BusUsagePredictor:
    def __init__(self, data_path, municipality_id, train_ratio=0.8, lstm_units=64, epochs=10, batch_size=32):
        self.data_path = data_path
        self.municipality_id = municipality_id
        self.train_ratio = train_ratio
        self.lstm_units = lstm_units
        self.epochs = epochs
        self.batch_size = batch_size
        self.data = None
        self.output_data = None
        self.x_train = None
        self.x_test = None
        self.y_train = None
        self.y_test = None
        self.model = None
        self.predictions = None

    def preprocess_data(self):
    # Gerekli sütunlar
        data = self.data[['usage', 'total_capacity']]

    # Veriyi ölçeklendirme
        scaler = MinMaxScaler()
        scaled_data = scaler.fit_transform(data)

    # Giriş ve çıkış verileri
        input_data = scaled_data[:, :-1]
        output_data = scaled_data[:, -1]
        self.output_data = output_data  

    # Verileri eğitim ve test 
        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(
        input_data, output_data, test_size=0.2, random_state=42
    )

    def build_model(self):
        # LSTM modelini oluşturun
        self.model = Sequential()
        self.model.add(LSTM(self.lstm_units, input_shape=(self.x_train.shape[1], 1)))
        self.model.add(Dense(1))
        self.model.compile(loss='mean_squared_error', optimizer='adam')

    def train_model(self):
        # Modeli eğitim
        self.model.fit(self.x_train, self.y_train, epochs=self.epochs, batch_size=self.batch_size)

    def predict(self):
        # Test veri seti üzerinde tahmin 
        test_input = self.x_test.reshape(self.x_test.shape[0], self.x_test.shape[1], 1)
        predictions = self.model.predict(test_input)

        # Tahminleri ters ölçeklendirme
        scaler = MinMaxScaler()
        scaler.fit(self.output_data.reshape(-1, 1))
        forecast_predictions = scaler.inverse_transform(predictions)

        return forecast_predictions

    def print_predictions(self):
    # Tahminleri dataframe olarak oluşturma
        forecast_df = pd.DataFrame(self.predictions, columns=self.data.columns[3:])
        print(forecast_df)

    # Tahminler
        for i, municipality_id in enumerate(self.data.columns[4:]):
          print('Municipality', municipality_id)
          print(self.predictions[:, i])  


    def load_data(self):    
        self.data = pd.read_csv(self.data_path)
        self.data = self.data[self.data['municipality_id'] == self.municipality_id]

    def run(self):
        self.load_data()
        self.preprocess_data()
        self.build_model()
        self.train_model()
        self.predictions = self.predict()
        self.print_predictions()



data_path = '/content/drive/MyDrive/municipality_bus_utilization_.csv'
municipality_id = 1
predictor = BusUsagePredictor(data_path, municipality_id)
predictor.run()

print(predictor.predictions)

from sklearn.metrics import mean_absolute_error

# MAE hesapla
mae = mean_absolute_error(test_output, predictions)
print('Mean Absolute Error:', mae)

last_data_point = data.iloc[-1]

last_date = last_data_point.name

forecast_dates = pd.date_range(start=last_date, periods=14, freq='D')[1:]

last_input = last_data_point[['usage', 'total_capacity']].values
last_input = scaler.transform(last_input.reshape(1, -1))

forecast_input = np.repeat(last_input, 14, axis=0)
forecast_input = forecast_input.reshape(forecast_input.shape[0], forecast_input.shape[1], 1)
forecast_predictions = model.predict(forecast_input)

forecast_predictions = scaler.inverse_transform(forecast_predictions)

forecast_df = pd.DataFrame(forecast_predictions, index=forecast_dates, columns=data.columns[4:])


print(forecast_df)

import pandas as pd

data_path = '/content/drive/MyDrive/municipality_bus_utilization_.csv'
data = pd.read_csv(data_path)

print(data.head())
print(data.columns)

